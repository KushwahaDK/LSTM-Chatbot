{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T19:41:18.498205Z",
     "start_time": "2020-08-15T19:41:10.909096Z"
    }
   },
   "source": [
    "##  General purpose Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Chatbot implemented using Seq2Seq ( Vanilla Encoder-Decoder architecture)\n",
    "#### 2. Built using LSTMs\n",
    "#### 3. Implemented in Tensorflow2.0+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:31:58.639159Z",
     "start_time": "2020-08-15T21:31:56.681189Z"
    }
   },
   "outputs": [],
   "source": [
    "# Building a deep NLP chatbot using seq2seq (Encoder Decoder architecture using LSTMs)\n",
    "\n",
    "# importing the required libraries\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input\n",
    "from tensorflow.keras.activations import softmax\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset used for making this general purpose Encoder decoder chatbot is \"Cornell Movie dialogs corpus\" where different sets of movie dialogs between two characters are provided from different movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:31:58.643127Z",
     "start_time": "2020-08-15T21:31:58.640134Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset folder path\n",
    "DATASET_PATH = 'dataset/cornell movie-dialogs corpus/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:31:59.349168Z",
     "start_time": "2020-08-15T21:31:58.644124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs : 1\n"
     ]
    }
   ],
   "source": [
    "#To check whether the Tensorflow is using or identifying the GPUs or not\",\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Number of available GPUs : {}\".format(len(physical_devices)))\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:31:59.461920Z",
     "start_time": "2020-08-15T21:31:59.352131Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reading the movie lines from the data\n",
    "lines_buff = open(os.path.join(DATASET_PATH,'movie_lines.txt'), mode='r', encoding='latin-1')\n",
    "lines = lines_buff.read().split('\\n')\n",
    "lines_buff.close()\n",
    "\n",
    "# Reading the conversation mappings from the data\n",
    "converasations_buff = open(os.path.join(DATASET_PATH,'movie_conversations.txt'), mode='r', encoding='latin-1')\n",
    "converasations = converasations_buff.read().split('\\n')\n",
    "converasations_buff.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:31:59.989436Z",
     "start_time": "2020-08-15T21:31:59.462830Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mapping each dialogie with the corresponding dialogue code in a dictionary for accessing easily    \n",
    "mapping_id2line = {}\n",
    "lines = [line.split(' +++$+++ ') for line in lines]\n",
    "for line in lines :\n",
    "    if len(line) == 5:\n",
    "        mapping_id2line[line[0]] = line[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:31:59.994421Z",
     "start_time": "2020-08-15T21:31:59.990431Z"
    }
   },
   "outputs": [],
   "source": [
    "# Verify the mapping of dialogies\n",
    "# mapping_id2line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:00.234862Z",
     "start_time": "2020-08-15T21:31:59.995419Z"
    }
   },
   "outputs": [],
   "source": [
    "# list of all conversations \n",
    "conversations_list = [converasation.split(' +++$+++ ')[-1][1:-1].strip().replace(\"'\",\"\").replace(\" \",\"\").split(',') for converasation in converasations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:00.239764Z",
     "start_time": "2020-08-15T21:32:00.236772Z"
    }
   },
   "outputs": [],
   "source": [
    "# Verify the list of all conversations\n",
    "# conversations_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:00.385376Z",
     "start_time": "2020-08-15T21:32:00.240761Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create questions and answers list to be trained based on the conversation pattern observed in data\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "for conversation in conversations_list[:-1] :\n",
    "    for i in range(len(conversation)-1): \n",
    "                questions.append(mapping_id2line[conversation[i]])\n",
    "                answers.append(mapping_id2line[conversation[i+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:00.394350Z",
     "start_time": "2020-08-15T21:32:00.386372Z"
    }
   },
   "outputs": [],
   "source": [
    "# Taking first 1 million dialogues to be used as questions from all questions list\n",
    "questions = questions[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:00.398340Z",
     "start_time": "2020-08-15T21:32:00.395348Z"
    }
   },
   "outputs": [],
   "source": [
    "# Verify the questions list\n",
    "# questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:00.407316Z",
     "start_time": "2020-08-15T21:32:00.399337Z"
    }
   },
   "outputs": [],
   "source": [
    "# Taking first 1 million dialogues to be used as answers from all answers list \n",
    "answers = answers[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:00.411305Z",
     "start_time": "2020-08-15T21:32:00.408313Z"
    }
   },
   "outputs": [],
   "source": [
    "# Verifying answers\n",
    "# answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:00.422275Z",
     "start_time": "2020-08-15T21:32:00.412304Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\" Function to clean the input text and return the cleaned text\n",
    "    \"\"\"\n",
    "    # lower case all text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # replace short words with complete words for consistency\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"don't\", \"do not\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"what is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    \n",
    "    # remove all non essential charachters\n",
    "    text = re.sub(r\"[-{}\\\"#/@;:<>()+=`|.?,]\",\"\", text)\n",
    "    #Or this to remove all characters except alphabets\n",
    "#     text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:01.562742Z",
     "start_time": "2020-08-15T21:32:00.423273Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the list of cleaned questions\n",
    "questions_cleaned = [clean_text(question) for question in questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:01.566694Z",
     "start_time": "2020-08-15T21:32:01.563700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Verify cleaned questions\n",
    "# questions_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:02.728671Z",
     "start_time": "2020-08-15T21:32:01.568696Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the list of cleaned anwers\n",
    "answers_cleaned = [clean_text(answer) for answer in answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:02.732573Z",
     "start_time": "2020-08-15T21:32:02.729581Z"
    }
   },
   "outputs": [],
   "source": [
    "# Verify cleaned answer\n",
    "# answers_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:02.838376Z",
     "start_time": "2020-08-15T21:32:02.733578Z"
    }
   },
   "outputs": [],
   "source": [
    "# truncating questions for maximum of 26 words\n",
    "truncated_questions = []\n",
    "for question in questions_cleaned:\n",
    "    truncated_questions.append(' '.join(question.split()[:26]).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:02.944045Z",
     "start_time": "2020-08-15T21:32:02.840295Z"
    }
   },
   "outputs": [],
   "source": [
    "# truncating answers for maximum of 26 words\n",
    "truncated_answers = []\n",
    "for answer in answers_cleaned:\n",
    "    truncated_answers.append(' '.join(answer.split()[:26]).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:02.953016Z",
     "start_time": "2020-08-15T21:32:02.945004Z"
    }
   },
   "outputs": [],
   "source": [
    "# Updating the cleaned questions and cleaned answers with truncated sentences\n",
    "questions_cleaned = truncated_questions\n",
    "answers_cleaned = truncated_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Remove rare words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:02.957970Z",
     "start_time": "2020-08-15T21:32:02.953980Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a word count dictionary for question and answer vocabulary to find the rarely occuring words\n",
    "count_mapping_dict = dict()\n",
    "def data_imporvement(text):\n",
    "    for word in text.split():\n",
    "        if word not in count_mapping_dict:\n",
    "            count_mapping_dict[word] = 1\n",
    "        else:\n",
    "            count_mapping_dict[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:03.203386Z",
     "start_time": "2020-08-15T21:32:02.960988Z"
    }
   },
   "outputs": [],
   "source": [
    "# find the question vocab counts\n",
    "for text in questions_cleaned:\n",
    "    data_imporvement(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:03.437275Z",
     "start_time": "2020-08-15T21:32:03.204345Z"
    }
   },
   "outputs": [],
   "source": [
    "# find the answers vocab counts\n",
    "for text in answers_cleaned:\n",
    "    data_imporvement(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:03.441218Z",
     "start_time": "2020-08-15T21:32:03.438226Z"
    }
   },
   "outputs": [],
   "source": [
    "# Verify the word count dictionary\n",
    "# count_mapping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:03.449208Z",
     "start_time": "2020-08-15T21:32:03.442218Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating threshold to filter out less frequent words\n",
    "# Filter out words from vocabulary whose count is less than the threshold\n",
    "# create a words to int dictionary for question words\n",
    "threshold = 40\n",
    "questionwords2int ={}\n",
    "word_number = 0\n",
    "for word, count in count_mapping_dict.items():\n",
    "         if count > threshold:\n",
    "            questionwords2int[word] =  word_number\n",
    "            word_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:03.456179Z",
     "start_time": "2020-08-15T21:32:03.450195Z"
    }
   },
   "outputs": [],
   "source": [
    "# Verify question words vocabulary to int mapping dictionary\n",
    "# questionwords2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:03.466152Z",
     "start_time": "2020-08-15T21:32:03.457176Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2613"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the length of mapping dict or the number of words in the question vocabulary\n",
    "len(questionwords2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:03.475133Z",
     "start_time": "2020-08-15T21:32:03.467149Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating threshold to filter out less frequent words\n",
    "# Filter out words from vocabulary whose count is less than the threshold\n",
    "# create a words to int dictionary for answer words\n",
    "threshold = 40\n",
    "answerwords2int = {}\n",
    "word_number = 0\n",
    "for word, count in count_mapping_dict.items():\n",
    "         if count > threshold:\n",
    "            answerwords2int[word] =  word_number\n",
    "            word_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:03.480129Z",
     "start_time": "2020-08-15T21:32:03.476157Z"
    }
   },
   "outputs": [],
   "source": [
    "# Verify answer words vocabulary to int mapping dictionary\n",
    "# answerwords2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:03.485101Z",
     "start_time": "2020-08-15T21:32:03.481118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2613"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the length of mapping dict or the number of words in the answer vocabulary\n",
    "len(answerwords2int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Add tokens for data preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:03.490095Z",
     "start_time": "2020-08-15T21:32:03.487126Z"
    }
   },
   "outputs": [],
   "source": [
    "# Token are used while encoding and decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:03.496112Z",
     "start_time": "2020-08-15T21:32:03.493083Z"
    }
   },
   "outputs": [],
   "source": [
    "# <SOS> Start of string\n",
    "# <EOS> End of String\n",
    "# <PAD> for maintaining the length of input\n",
    "# <OUT> for words not used while training(filter out)\n",
    "tokens = ['<PAD>', '<EOS>', '<OUT>', '<SOS>']\n",
    "\n",
    "# adding token and corresponding integer mapping to existing word to integer mapping for questions\n",
    "for token in tokens:\n",
    "    questionwords2int[token] = len(questionwords2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:03.501059Z",
     "start_time": "2020-08-15T21:32:03.497068Z"
    }
   },
   "outputs": [],
   "source": [
    "# adding token and corresponding integer mapping to existing word to integer mapping for answers\n",
    "for token in tokens:\n",
    "    answerwords2int[token] = len(answerwords2int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating an inverse index to words dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:03.505047Z",
     "start_time": "2020-08-15T21:32:03.502055Z"
    }
   },
   "outputs": [],
   "source": [
    "# create an inverse dictionary of answers2int for decoder so that after predicting the owrd index we can create the words\n",
    "int2answerwords = {i:w for w,i in answerwords2int.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding  tags for decoder training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:03.510035Z",
     "start_time": "2020-08-15T21:32:03.506047Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adding <SOS> at the start of answers sentence and <EOS> at the end of every answer sentence for decoder to learn where to stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:03.537007Z",
     "start_time": "2020-08-15T21:32:03.511032Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(answers_cleaned)):\n",
    "    answers_cleaned[i] = '<SOS> '+ answers_cleaned[i] + ' <EOS>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:03.540977Z",
     "start_time": "2020-08-15T21:32:03.537959Z"
    }
   },
   "outputs": [],
   "source": [
    "# Verify the updated data\n",
    "# answers_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Translate all the question and answers into integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:03.958027Z",
     "start_time": "2020-08-15T21:32:03.541948Z"
    }
   },
   "outputs": [],
   "source": [
    "# Converting question setences to integer encoding\n",
    "question_to_int = []\n",
    "for question in questions_cleaned:\n",
    "    ints = []\n",
    "    for word in question.split():\n",
    "        if word not in questionwords2int:\n",
    "            ints.append(questionwords2int['<OUT>'])\n",
    "        else:\n",
    "            ints.append(questionwords2int[word])\n",
    "    question_to_int.append(ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:04.244972Z",
     "start_time": "2020-08-15T21:32:03.958986Z"
    }
   },
   "outputs": [],
   "source": [
    "# Converting answer setences to integer encoding\n",
    "answer_to_int = []\n",
    "for answer in answers_cleaned:\n",
    "    ints = []\n",
    "    for word in answer.split():\n",
    "        if word not in answerwords2int:\n",
    "            ints.append(answerwords2int['<OUT>'])\n",
    "        else:\n",
    "            ints.append(answerwords2int[word])\n",
    "    answer_to_int.append(ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:04.258896Z",
     "start_time": "2020-08-15T21:32:04.245931Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the length of longest question to be used for encode model input\n",
    "question_sequence_length = max([len(question) for question in question_to_int])\n",
    "question_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:04.275886Z",
     "start_time": "2020-08-15T21:32:04.259906Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the length of longest answer to be used for decoder model input\n",
    "answer_sequence_length = max([len(answer) for answer in answer_to_int])\n",
    "answer_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:05.199246Z",
     "start_time": "2020-08-15T21:32:04.276895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 100)    261700      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    261700      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 100), (None, 80400       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 100),  80400       embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 2617)   264317      lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 948,517\n",
      "Trainable params: 948,517\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the LSTM based Encoder-Decoder model using Keras Functional API\n",
    "# dimension of embedding layer\n",
    "EMBED_HID_DIM = 100\n",
    "\n",
    "# dimension of LSTM unit\n",
    "latent_dim = 100\n",
    "\n",
    "# Size of questions and answers vocab\n",
    "vocab_questions = len(questionwords2int)\n",
    "vocab_answers = len(answerwords2int)\n",
    "\n",
    "# Encoder Model creationS\n",
    "# Define an input shape.\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# Define the embedding layer\n",
    "inputs_embed = Embedding(input_dim=vocab_questions, output_dim=EMBED_HID_DIM, input_length=question_sequence_length)\n",
    "encoder_embed = inputs_embed(encoder_inputs)\n",
    "\n",
    "# DEFINE THE LSTM layer\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_embed)\n",
    "\n",
    "# create the encoder model\n",
    "model = Model(encoder_inputs, encoder_outputs)\n",
    "\n",
    "\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "\n",
    "#decoder input shape\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# define decoder embedding layer\n",
    "decode_inputs_embed = Embedding(input_dim=vocab_answers, output_dim=EMBED_HID_DIM, input_length=answer_sequence_length)\n",
    "decoder_embed = decode_inputs_embed(decoder_inputs)\n",
    "\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the \n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embed,\n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "# Final classifier layer Dense and softmax activated\n",
    "decoder_dense = Dense(vocab_answers, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:05.213200Z",
     "start_time": "2020-08-15T21:32:05.200209Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compile the Keras model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preperation for model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:05.839537Z",
     "start_time": "2020-08-15T21:32:05.214172Z"
    }
   },
   "outputs": [],
   "source": [
    "# Padding of Integer coded question and answers with <PAD> sequence\n",
    "def padding(encoder_sequences, decoder_sequences):\n",
    "    \n",
    "    encoder_input_data = pad_sequences(encoder_sequences, maxlen=question_sequence_length, dtype='int32', padding='post', truncating='post', value= questionwords2int['<PAD>'])\n",
    "    decoder_input_data = pad_sequences(decoder_sequences, maxlen=answer_sequence_length, dtype='int32', padding='post', truncating='post', value= answerwords2int['<PAD>'])\n",
    "  \n",
    "    return encoder_input_data, decoder_input_data\n",
    "\n",
    "encoder_input_data, decoder_input_data = padding(question_to_int, answer_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:05.843488Z",
     "start_time": "2020-08-15T21:32:05.840509Z"
    }
   },
   "outputs": [],
   "source": [
    "# Verify Encoder input after padding\n",
    "# encoder_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:05.849476Z",
     "start_time": "2020-08-15T21:32:05.844502Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 26)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify encoder input shape\n",
    "encoder_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:05.855470Z",
     "start_time": "2020-08-15T21:32:05.851469Z"
    }
   },
   "outputs": [],
   "source": [
    "# Verify Decoder input after padding\n",
    "# decoder_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:05.861440Z",
     "start_time": "2020-08-15T21:32:05.857451Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 28)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify encoder input shape\n",
    "decoder_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:05.869450Z",
     "start_time": "2020-08-15T21:32:05.862438Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to generate batch of training data based on batch size becuase dataset is too big to fit in memory\n",
    "# encoder_input_data = as is it\n",
    "# decoder_input data = as it is\n",
    "# decoder_target_data = offset by one timestep\n",
    "\n",
    "max_source_length = question_sequence_length\n",
    "max_target_length = answer_sequence_length\n",
    "num_decoder_tokens = vocab_answers\n",
    "\n",
    "def generate_batch(X , y , batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "\n",
    "            encoder_input_data = np.zeros((batch_size, max_source_length),dtype='int32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_target_length),dtype='int32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_target_length, num_decoder_tokens),dtype='int32')\n",
    "\n",
    "            for i, (input_seq, target_seq) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_seq):\n",
    "                    encoder_input_data[i, t] = word\n",
    "                for t, word in enumerate(target_seq):\n",
    "                    if t<len(target_seq)-1:\n",
    "                        decoder_input_data[i, t] = word # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        #print(word)\n",
    "                        decoder_target_data[i, t - 1, word] = 1.\n",
    "\n",
    "\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:05.878395Z",
     "start_time": "2020-08-15T21:32:05.871432Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model training configuration\n",
    "train_samples = len(question_to_int) # Total Training samples\n",
    "batch_size = 128\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:32:05.883381Z",
     "start_time": "2020-08-15T21:32:05.879393Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = encoder_input_data\n",
    "y_train = decoder_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:56:29.072285Z",
     "start_time": "2020-08-15T21:32:05.884378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "781/781 [==============================] - 59s 75ms/step - loss: 2.2177 - acc: 0.6205\n",
      "Epoch 2/25\n",
      "781/781 [==============================] - 59s 75ms/step - loss: 1.8264 - acc: 0.6478\n",
      "Epoch 3/25\n",
      "781/781 [==============================] - 59s 76ms/step - loss: 1.7196 - acc: 0.6595\n",
      "Epoch 4/25\n",
      "781/781 [==============================] - 59s 76ms/step - loss: 1.6734 - acc: 0.6627\n",
      "Epoch 5/25\n",
      "781/781 [==============================] - 59s 76ms/step - loss: 1.6430 - acc: 0.6647\n",
      "Epoch 6/25\n",
      "781/781 [==============================] - 59s 76ms/step - loss: 1.6208 - acc: 0.6665\n",
      "Epoch 7/25\n",
      "781/781 [==============================] - 58s 74ms/step - loss: 1.6038 - acc: 0.6679\n",
      "Epoch 8/25\n",
      "781/781 [==============================] - 58s 74ms/step - loss: 1.5903 - acc: 0.6690\n",
      "Epoch 9/25\n",
      "781/781 [==============================] - 58s 74ms/step - loss: 1.5789 - acc: 0.6698\n",
      "Epoch 10/25\n",
      "781/781 [==============================] - 58s 74ms/step - loss: 1.5687 - acc: 0.6705\n",
      "Epoch 11/25\n",
      "781/781 [==============================] - 58s 74ms/step - loss: 1.5604 - acc: 0.6711\n",
      "Epoch 12/25\n",
      "781/781 [==============================] - 58s 74ms/step - loss: 1.5520 - acc: 0.6719\n",
      "Epoch 13/25\n",
      "781/781 [==============================] - 58s 75ms/step - loss: 1.5446 - acc: 0.6725\n",
      "Epoch 14/25\n",
      "781/781 [==============================] - 58s 74ms/step - loss: 1.5379 - acc: 0.6730\n",
      "Epoch 15/25\n",
      "781/781 [==============================] - 58s 74ms/step - loss: 1.5316 - acc: 0.6735\n",
      "Epoch 16/25\n",
      "781/781 [==============================] - 58s 74ms/step - loss: 1.5250 - acc: 0.6741\n",
      "Epoch 17/25\n",
      "781/781 [==============================] - 58s 74ms/step - loss: 1.5198 - acc: 0.6744\n",
      "Epoch 18/25\n",
      "781/781 [==============================] - 58s 74ms/step - loss: 1.5140 - acc: 0.6749\n",
      "Epoch 19/25\n",
      "781/781 [==============================] - 58s 74ms/step - loss: 1.5098 - acc: 0.6751\n",
      "Epoch 20/25\n",
      "781/781 [==============================] - 58s 74ms/step - loss: 1.5053 - acc: 0.6755\n",
      "Epoch 21/25\n",
      "781/781 [==============================] - 61s 78ms/step - loss: 1.5007 - acc: 0.6759\n",
      "Epoch 22/25\n",
      "781/781 [==============================] - 58s 75ms/step - loss: 1.4960 - acc: 0.6763\n",
      "Epoch 23/25\n",
      "781/781 [==============================] - 58s 75ms/step - loss: 1.4924 - acc: 0.6766\n",
      "Epoch 24/25\n",
      "781/781 [==============================] - 58s 74ms/step - loss: 1.4881 - acc: 0.6769\n",
      "Epoch 25/25\n",
      "781/781 [==============================] - 58s 74ms/step - loss: 1.4838 - acc: 0.6774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a4b5ac42c8>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model fit\n",
    "model.fit(generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:57:06.047670Z",
     "start_time": "2020-08-15T21:57:05.975690Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the model to disk\n",
    "model.save('model/LSTM_chatbot.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Inference with Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:57:08.686849Z",
     "start_time": "2020-08-15T21:57:08.521207Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the \"Context vectors\"\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_state_input = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2 = decode_inputs_embed(decoder_inputs)\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_state_input)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_state_input,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:57:09.288498Z",
     "start_time": "2020-08-15T21:57:09.282540Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to decode the sequence from a decoder given the input sequence\n",
    "def decode_sequence(input_seq):\n",
    "        # Encode the input as state vectors.\n",
    "        states_value = encoder_model.predict(input_seq)\n",
    "        \n",
    "        # Generate empty target sequence of length 1.\n",
    "        target_seq = np.zeros((1,1))\n",
    "        \n",
    "        # Populate the first character of \n",
    "        #target sequence with the start character.\n",
    "        target_seq[0, 0] = answerwords2int['<SOS>']\n",
    "        \n",
    "        # Sampling loop for a batch of sequences\n",
    "        # (to simplify, here we assume a batch of size 1).\n",
    "        stop_condition = False\n",
    "        decoded_sentence = ''\n",
    "        \n",
    "        while not stop_condition:\n",
    "            output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "            \n",
    "            # Sample a token\n",
    "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "            sampled_word =int2answerwords[sampled_token_index]\n",
    "            decoded_sentence += ' '+ sampled_word\n",
    "            \n",
    "            # Exit condition: either hit max length\n",
    "            # or find stop character.\n",
    "            if (sampled_word == '<EOS>' or len(decoded_sentence.split()) > 25):\n",
    "                stop_condition = True\n",
    "        \n",
    "            # Update the target sequence (of length 1).\n",
    "            target_seq = np.zeros((1,1))\n",
    "            target_seq[0, 0] = sampled_token_index\n",
    "            \n",
    "            # Update states\n",
    "            states_value = [h, c]\n",
    "        return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make inference on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:57:10.660832Z",
     "start_time": "2020-08-15T21:57:10.656809Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a batch generator for batch size 1\n",
    "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T21:59:21.550372Z",
     "start_time": "2020-08-15T21:59:21.373873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Source sentence: she okay\n",
      "Actual Target Sentence:  i hope so \n",
      "Predicted Target Sentence: i am not sure\n"
     ]
    }
   ],
   "source": [
    "# Predict the target sentence and compare with the actual target sentence given a source sentence\n",
    "k+=1\n",
    "(input_seq, actual_output), target_output = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input Source sentence:',questions_cleaned[k:k+1][0])\n",
    "print('Actual Target Sentence:', answers_cleaned[k:k+1][0][5:-5])\n",
    "print('Predicted Target Sentence:', decoded_sentence[:-5].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
